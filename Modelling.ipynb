{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "import random\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Courtesy: AAIC\n",
    "\n",
    "def get_error_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean([(y_true[i] - y_pred[i])**2 for i in range(len(y_pred))]))\n",
    "    mape = np.mean(np.abs( (y_true - y_pred)/y_true )) * 100\n",
    "    return rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the training data\n",
    "x_train = pd.read_csv('./dataset/train_10000_1000.csv',\n",
    "                     names = ['user', 'movie',\n",
    "                                    'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "                                    'sur6', 'sur7', 'sur8', 'sur9', 'sur10',\n",
    "                                    'smr1', 'smr2', 'smr3', 'smr4', 'smr5',\n",
    "                                    'smr6', 'smr7', 'smr8', 'smr9', 'smr10',\n",
    "                                    'MAvg', 'UAvg', 'GAvg', 'rating'], header=None)\n",
    "\n",
    "x_train.drop(['user', 'movie'], axis=1, inplace=True)\n",
    "y_train = x_train.rating\n",
    "x_train.drop(['rating'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the testing data\n",
    "x_test = pd.read_csv('./dataset/test_10000_1000.csv', \n",
    "                    names = ['user', 'movie',\n",
    "                                    'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "                                    'sur6', 'sur7', 'sur8', 'sur9', 'sur10',\n",
    "                                    'smr1', 'smr2', 'smr3', 'smr4', 'smr5',\n",
    "                                    'smr6', 'smr7', 'smr8', 'smr9', 'smr10',\n",
    "                                    'MAvg', 'UAvg', 'GAvg', 'rating'], header=None)\n",
    "x_test.drop(['user', 'movie'], axis=1, inplace=True)\n",
    "y_test = x_test.rating\n",
    "x_test.drop(['rating'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129286, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36017, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb(train_frames, test_frames, eval_metric, tuning=False, var_imp=False, **kwargs):\n",
    "    \"\"\"\n",
    "    It runs XGBoost with the `training_frames` and reports the `eval_metric`\n",
    "    on the `test_frame`. It can also plot the variable importance if `var_imp` is true.\n",
    "    It also performs hyperparam tuning if `tuning` is true.\n",
    "    \"\"\"\n",
    "    x_train, y_train = train_frames\n",
    "    x_test, y_test = test_frames\n",
    "    jobs = kwargs.get('n_jobs', -1)\n",
    "    rs = kwargs.get('rs', 42)\n",
    "    model = kwargs.get('model', None)\n",
    "    if model is None:\n",
    "        model = xgb.XGBRegressor(n_jobs=jobs, random_state=rs)\n",
    "    if tuning:\n",
    "        prams = {\n",
    "             'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.15, 0.2],\n",
    "             'n_estimators': [100, 200, 500, 1000, 2000],\n",
    "             'max_depth': [3, 5, 10],\n",
    "             'colsample_bytree': [0.1, 0.3, 0.5, 1],\n",
    "             'subsample': [0.1, 0.3, 0.5, 1]\n",
    "        }\n",
    "        cv = kwargs.get('cv', 2)\n",
    "        random_cfl = RandomizedSearchCV(model, param_distributions=prams, \n",
    "                                        verbose=2, n_jobs=-1, cv=cv,\n",
    "                                       scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
    "                                               'explained_variance', 'r2'],\n",
    "                                       refit='neg_mean_squared_error')\n",
    "        model = random_cfl\n",
    "    if isinstance(model, xgb.sklearn.XGBRegressor):\n",
    "        model.fit(x_train, y_train, eval_metric='rmse', verbose=True)\n",
    "        # Get the training results\n",
    "        y_train_pred = model.predict(x_train)\n",
    "        rmse_train, mape_train = eval_metric(y_train.values, y_train_pred)\n",
    "        train_results = {'rmse': rmse_train,\n",
    "                        'mape' : mape_train}\n",
    "\n",
    "        # Get the testing results\n",
    "        y_test_pred = model.predict(x_test) \n",
    "        rmse_test, mape_test = eval_metric(y_test.values, y_test_pred)\n",
    "        test_results = {'rmse': rmse_test,\n",
    "                        'mape' : mape_test}\n",
    "\n",
    "    elif isinstance(model, RandomizedSearchCV):\n",
    "        model.fit(x_train, y_train)\n",
    "        best_model = model.best_estimator_\n",
    "        # Get the training results\n",
    "        y_train_pred = best_model.predict(x_train)\n",
    "        rmse_train, mape_train = eval_metric(y_train.values, y_train_pred)\n",
    "        train_results = {'rmse': rmse_train,\n",
    "                        'mape' : mape_train}\n",
    "\n",
    "        # Get the testing results\n",
    "        y_test_pred = best_model.predict(x_test) \n",
    "        rmse_test, mape_test = eval_metric(y_test.values, y_test_pred)\n",
    "        test_results = {'rmse': rmse_test,\n",
    "                        'mape' : mape_test}\n",
    "    return train_results, test_results, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 s, sys: 44 ms, total: 21.7 s\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trr, tsr, _ = run_xgb(train_frames=(x_train, y_train), test_frames=(x_test, y_test), \n",
    "        eval_metric=get_error_metrics, tuning=False, n_jobs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 24.95936775643008, 'rmse': 0.8367030215239278}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 35.91318104810172, 'rmse': 1.1030815541160461}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:   56.4s remaining:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 15.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.5 s, sys: 360 ms, total: 48.9 s\n",
      "Wall time: 15min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trr, tsr, model = run_xgb(train_frames=(x_train, y_train), test_frames=(x_test, y_test), \n",
    "        eval_metric=get_error_metrics, tuning=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 24.364184919431214, 'rmse': 0.822279872042983}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 34.187791961329296, 'rmse': 1.1550337863181954}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.1,\n",
       " 'learning_rate': 0.15,\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 1000,\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_less = x_train.drop(['sur6', 'sur7', 'sur8', 'sur9', 'sur10',\n",
    "             'smr6', 'smr7', 'smr8', 'smr9', 'smr10'], axis=1)\n",
    "x_test_less = x_test.drop(['sur6', 'sur7', 'sur8', 'sur9', 'sur10',\n",
    "             'smr6', 'smr7', 'smr8', 'smr9', 'smr10'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:   44.1s remaining:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.9 s, sys: 416 ms, total: 39.4 s\n",
      "Wall time: 12min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trr, tsr, model = run_xgb(train_frames=(x_train_less, y_train), test_frames=(x_test_less, y_test), \n",
    "        eval_metric=get_error_metrics, tuning=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 25.19446355233596, 'rmse': 0.844005927313099}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 35.63025169406275, 'rmse': 1.1082421026611329}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "prams = {\n",
    "             'reg_alpha': [0.001, 0.003, 0.005, 0.008, 0.01]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cfl = GridSearchCV(model.best_estimator_, param_grid=prams, \n",
    "                                        verbose=2, n_jobs=-1, cv=2,\n",
    "                                       scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
    "                                               'explained_variance', 'r2'],\n",
    "                                       refit='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:   34.1s remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   40.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=42,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'reg_alpha': [0.001, 0.003, 0.005, 0.008, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit='neg_mean_squared_error',\n",
       "       return_train_score='warn',\n",
       "       scoring=['neg_mean_squared_error', 'neg_mean_absolute_error', 'explained_variance', 'r2'],\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cfl.fit(x_train_less, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_cfl.best_estimator_\n",
    "y_train_pred = best_model.predict(x_train_less)\n",
    "rmse_train, mape_train = get_error_metrics(y_train.values, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8440662455906432"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.197463780748354"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(x_test_less)\n",
    "rmse_test, mape_test = get_error_metrics(y_test.values, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1088560249897377"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.595289820630754"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_alpha': 0.01}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cfl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Courtesy: AAIC\n",
    "\n",
    "# it is just to makesure that all of our algorithms should produce same results\n",
    "# everytime they run...\n",
    "\n",
    "my_seed = 15\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "##########################################################\n",
    "# get  (actual_list , predicted_list) ratings given list \n",
    "# of predictions (prediction is a class in Surprise).    \n",
    "##########################################################\n",
    "def get_ratings(predictions):\n",
    "    actual = np.array([pred.r_ui for pred in predictions])\n",
    "    pred = np.array([pred.est for pred in predictions])\n",
    "    \n",
    "    return actual, pred\n",
    "\n",
    "################################################################\n",
    "# get ''rmse'' and ''mape'' , given list of prediction objecs \n",
    "################################################################\n",
    "def get_errors(predictions, print_them=False):\n",
    "\n",
    "    actual, pred = get_ratings(predictions)\n",
    "    rmse = np.sqrt(np.mean((pred - actual)**2))\n",
    "    mape = np.mean(np.abs(pred - actual)/actual)\n",
    "\n",
    "    return rmse, mape*100\n",
    "\n",
    "##################################################################################\n",
    "# It will return predicted ratings, rmse and mape of both train and test data   #\n",
    "##################################################################################\n",
    "def run_surprise(algo, trainset, testset, verbose=True): \n",
    "    '''\n",
    "        return train_dict, test_dict\n",
    "    \n",
    "        It returns two dictionaries, one for train and the other is for test\n",
    "        Each of them have 3 key-value pairs, which specify ''rmse'', ''mape'', and ''predicted ratings''.\n",
    "    '''\n",
    "    start = datetime.now()\n",
    "    # dictionaries that stores metrics for train and test..\n",
    "    train = dict()\n",
    "    test = dict()\n",
    "    \n",
    "    # train the algorithm with the trainset\n",
    "    st = datetime.now()\n",
    "    if verbose:\n",
    "        print('Training the model...')\n",
    "    algo.fit(trainset)\n",
    "    if verbose:\n",
    "        print('Done. time taken : {} \\n'.format(datetime.now()-st))\n",
    "    \n",
    "    # ---------------- Evaluating train data--------------------#\n",
    "    st = datetime.now()\n",
    "    if verbose:\n",
    "        print('Evaluating the model with train data..')\n",
    "    # get the train predictions (list of prediction class inside Surprise)\n",
    "    train_preds = algo.test(trainset.build_testset())\n",
    "    # get predicted ratings from the train predictions..\n",
    "    train_actual_ratings, train_pred_ratings = get_ratings(train_preds)\n",
    "    # get ''rmse'' and ''mape'' from the train predictions.\n",
    "    train_rmse, train_mape = get_errors(train_preds)\n",
    "    if verbose:\n",
    "        print('time taken : {}'.format(datetime.now()-st))\n",
    "    \n",
    "    if verbose:\n",
    "        print('-'*15)\n",
    "        print('Train Data')\n",
    "        print('-'*15)\n",
    "        print(\"RMSE : {}\\n\\nMAPE : {}\\n\".format(train_rmse, train_mape))\n",
    "    \n",
    "    #store them in the train dictionary\n",
    "    if verbose:\n",
    "        print('adding train results in the dictionary..')\n",
    "    train['rmse'] = train_rmse\n",
    "    train['mape'] = train_mape\n",
    "    train['predictions'] = train_pred_ratings\n",
    "    \n",
    "    #------------ Evaluating Test data---------------#\n",
    "    st = datetime.now()\n",
    "    if verbose:\n",
    "        print('\\nEvaluating for test data...')\n",
    "    # get the predictions( list of prediction classes) of test data\n",
    "    test_preds = algo.test(testset)\n",
    "    # get the predicted ratings from the list of predictions\n",
    "    test_actual_ratings, test_pred_ratings = get_ratings(test_preds)\n",
    "    # get error metrics from the predicted and actual ratings\n",
    "    test_rmse, test_mape = get_errors(test_preds)\n",
    "    if verbose:\n",
    "        print('time taken : {}'.format(datetime.now()-st))\n",
    "    \n",
    "    if verbose:\n",
    "        print('-'*15)\n",
    "        print('Test Data')\n",
    "        print('-'*15)\n",
    "        print(\"RMSE : {}\\n\\nMAPE : {}\\n\".format(test_rmse, test_mape))\n",
    "    # store them in test dictionary\n",
    "    if verbose:\n",
    "        print('storing the test results in test dictionary...')\n",
    "    test['rmse'] = test_rmse\n",
    "    test['mape'] = test_mape\n",
    "    test['predictions'] = test_pred_ratings\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\n'+'-'*45)\n",
    "        print('Total time taken to run this algorithm :', datetime.now() - start)\n",
    "    \n",
    "    # return two dictionaries train and test\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly, Reader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>sur6</th>\n",
       "      <th>sur7</th>\n",
       "      <th>sur8</th>\n",
       "      <th>...</th>\n",
       "      <th>smr5</th>\n",
       "      <th>smr6</th>\n",
       "      <th>smr7</th>\n",
       "      <th>smr8</th>\n",
       "      <th>smr9</th>\n",
       "      <th>smr10</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2562859</td>\n",
       "      <td>4356</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.684725</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>769577</td>\n",
       "      <td>6673</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.976744</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1134808</td>\n",
       "      <td>8301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.076835</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1677588</td>\n",
       "      <td>3196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.730769</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>319758</td>\n",
       "      <td>7635</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>2.908390</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  movie  sur1  sur2  sur3  sur4  sur5  sur6  sur7  sur8   ...    \\\n",
       "0  2562859   4356   4.0   3.0   4.0   5.0   3.0   4.0   3.0   3.0   ...     \n",
       "1   769577   6673   4.0   4.0   3.0   4.0   3.0   2.0   3.0   3.0   ...     \n",
       "2  1134808   8301   1.0   4.0   1.0   4.0   4.0   4.0   4.0   2.0   ...     \n",
       "3  1677588   3196   1.0   4.0   3.0   3.0   2.0   3.0   3.0   3.0   ...     \n",
       "4   319758   7635   5.0   1.0   2.0   3.0   3.0   2.0   4.0   3.0   ...     \n",
       "\n",
       "   smr5      smr6      smr7      smr8      smr9     smr10      MAvg      UAvg  \\\n",
       "0   5.0  5.000000  2.000000  3.000000  4.000000  5.000000  3.684725  3.333333   \n",
       "1   3.0  3.333333  3.333333  3.333333  3.333333  3.333333  2.976744  3.333333   \n",
       "2   4.0  3.000000  4.000000  4.000000  3.000000  4.000000  3.076835  3.250000   \n",
       "3   3.0  3.000000  2.000000  3.000000  2.000000  2.000000  2.730769  2.660000   \n",
       "4   4.4  4.400000  4.400000  4.400000  4.400000  4.400000  2.908390  4.400000   \n",
       "\n",
       "       GAvg  rating  \n",
       "0  3.581679       3  \n",
       "1  3.581679       2  \n",
       "2  3.581679       2  \n",
       "3  3.581679       1  \n",
       "4  3.581679       2  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_train = pd.read_csv('./dataset/train_10000_1000.csv',\n",
    "                     names = ['user', 'movie',\n",
    "                                    'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "                                    'sur6', 'sur7', 'sur8', 'sur9', 'sur10',\n",
    "                                    'smr1', 'smr2', 'smr3', 'smr4', 'smr5',\n",
    "                                    'smr6', 'smr7', 'smr8', 'smr9', 'smr10',\n",
    "                                    'MAvg', 'UAvg', 'GAvg', 'rating'], header=None)\n",
    "reg_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>sur6</th>\n",
       "      <th>sur7</th>\n",
       "      <th>sur8</th>\n",
       "      <th>...</th>\n",
       "      <th>smr5</th>\n",
       "      <th>smr6</th>\n",
       "      <th>smr7</th>\n",
       "      <th>smr8</th>\n",
       "      <th>smr9</th>\n",
       "      <th>smr10</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1371302</td>\n",
       "      <td>1962</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>...</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1592891</td>\n",
       "      <td>4931</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>...</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>808635</td>\n",
       "      <td>71</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>...</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>427178</td>\n",
       "      <td>5226</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>...</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>942784</td>\n",
       "      <td>5768</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>...</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  movie      sur1      sur2      sur3      sur4      sur5      sur6  \\\n",
       "0  1371302   1962  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "1  1592891   4931  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "2   808635     71  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "3   427178   5226  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "4   942784   5768  3.581679  3.581679  3.581679  3.581679  3.581679  3.581679   \n",
       "\n",
       "       sur7      sur8   ...        smr5      smr6      smr7      smr8  \\\n",
       "0  3.581679  3.581679   ...    3.581679  3.581679  3.581679  3.581679   \n",
       "1  3.581679  3.581679   ...    3.581679  3.581679  3.581679  3.581679   \n",
       "2  3.581679  3.581679   ...    3.581679  3.581679  3.581679  3.581679   \n",
       "3  3.581679  3.581679   ...    3.581679  3.581679  3.581679  3.581679   \n",
       "4  3.581679  3.581679   ...    3.581679  3.581679  3.581679  3.581679   \n",
       "\n",
       "       smr9     smr10      MAvg      UAvg      GAvg  rating  \n",
       "0  3.581679  3.581679  3.581679  3.581679  3.581679       3  \n",
       "1  3.581679  3.581679  3.581679  3.581679  3.581679       1  \n",
       "2  3.581679  3.581679  3.581679  3.581679  3.581679       5  \n",
       "3  3.581679  3.581679  3.581679  3.581679  3.581679       5  \n",
       "4  3.581679  3.581679  3.581679  3.581679  3.581679       4  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_test = pd.read_csv('./dataset/test_10000_1000.csv', \n",
    "                    names = ['user', 'movie',\n",
    "                                    'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "                                    'sur6', 'sur7', 'sur8', 'sur9', 'sur10',\n",
    "                                    'smr1', 'smr2', 'smr3', 'smr4', 'smr5',\n",
    "                                    'smr6', 'smr7', 'smr8', 'smr9', 'smr10',\n",
    "                                    'MAvg', 'UAvg', 'GAvg', 'rating'], header=None)\n",
    "reg_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))\n",
    "train_data = Dataset.load_from_df(reg_train[['user', 'movie', 'rating']], reader)\n",
    "trainset = train_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1371302, 1962, 3), (1592891, 4931, 1), (808635, 71, 5)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = list(zip(reg_test.user.values, reg_test.movie.values, reg_test.rating.values))\n",
    "testset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options are to specify.., how to compute those user and item biases\n",
    "scores = {}\n",
    "for lr in [10, 1, 0.1, 0.01, 0.03, 0.05, 0.07, \n",
    "           0.001, 0.003, 0.005, 0.007, 0.0001]:\n",
    "    bsl_options = {'method': 'sgd',\n",
    "                   'learning_rate': lr}\n",
    "    bsl_algo = BaselineOnly(bsl_options=bsl_options, verbose=False)\n",
    "    # run this algorithm.., It will return the train and test results..\n",
    "    bsl_train_results, bsl_test_results = run_surprise(bsl_algo, trainset, testset, verbose=False)\n",
    "    scores[lr] = bsl_test_results['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.003, 1.0995129545071682),\n",
       " (0.005, 1.099571571436182),\n",
       " (0.001, 1.0995924446993357),\n",
       " (0.007, 1.0996405000418235),\n",
       " (0.01, 1.0997239026072736),\n",
       " (0.0001, 1.100100052985354),\n",
       " (0.03, 1.100166435301005),\n",
       " (0.05, 1.1008505276616793),\n",
       " (0.07, 1.1016934711260267),\n",
       " (0.1, 1.1029808636311582),\n",
       " (10, 1.1748347151296556),\n",
       " (1, 1.244444193747045)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsl_options = {'method': 'sgd',\n",
    "                   'learning_rate': 0.003}\n",
    "bsl_algo = BaselineOnly(bsl_options=bsl_options, verbose=False)\n",
    "# run this algorithm.., It will return the train and test results..\n",
    "bsl_train_results, bsl_test_results = run_surprise(bsl_algo, trainset, testset, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 36.30015233426039,\n",
       " 'predictions': array([3.58167938, 3.58167938, 3.58167938, ..., 4.02737251, 3.58167938,\n",
       "        4.02737251]),\n",
       " 'rmse': 1.0995129545071682}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsl_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['bslpr'] = bsl_train_results['predictions']\n",
    "x_test['bslpr'] = bsl_test_results['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 20s, sys: 64 ms, total: 3min 20s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = xgb.XGBRegressor(n_jobs=16, random_state=42, n_estimators=1000, colsample_bytree=0.1, learning_rate=0.15,\n",
    "                        max_depth=3, subsample=0.5, reg_alpha=0.01)\n",
    "model.fit(x_train, y_train, eval_metric='rmse', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8216051866429652 24.316092284899497\n",
      "1.1089055660379303 35.67581325824863\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "rmse_train, mape_train = get_error_metrics(y_train.values, y_train_pred)\n",
    "print(rmse_train, mape_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "rmse_test, mape_test = get_error_metrics(y_test.values, y_test_pred)\n",
    "print(rmse_test, mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57min 5s, sys: 49.4 s, total: 57min 55s\n",
      "Wall time: 57min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# we specify , how to compute similarities and what to consider with sim_options to our algorithm\n",
    "sim_options = {'user_based' : True,\n",
    "               'name': 'pearson_baseline',\n",
    "               'shrinkage': 100,\n",
    "               'min_support': 2\n",
    "              } \n",
    "# we keep other parameters like regularization parameter and learning_rate as default values.\n",
    "bsl_options = {'method': 'sgd'} \n",
    "scores = {}\n",
    "for k in range(10, 100, 5):\n",
    "    knn_bsl_u = KNNBaseline(k=k, sim_options = sim_options, bsl_options = bsl_options, verbose=False)\n",
    "    knn_bsl_u_train_results, knn_bsl_u_test_results = run_surprise(knn_bsl_u, trainset, testset, verbose=False)\n",
    "    scores[k] = knn_bsl_u_test_results['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20, 1.0995512454225425),\n",
       " (40, 1.0995532873955698),\n",
       " (85, 1.0995537021654327),\n",
       " (80, 1.0995539465826385),\n",
       " (45, 1.0995540106627826),\n",
       " (90, 1.0995550723491567),\n",
       " (35, 1.0995553398547928),\n",
       " (25, 1.0995564006444158),\n",
       " (50, 1.09955666951909),\n",
       " (95, 1.0995569944680081),\n",
       " (65, 1.0995571268377984),\n",
       " (60, 1.099557129081337),\n",
       " (75, 1.0995573024293464),\n",
       " (55, 1.099557450682997),\n",
       " (70, 1.0995576968458285),\n",
       " (30, 1.0995578984311523),\n",
       " (15, 1.0995620654788676),\n",
       " (10, 1.0995761058471643)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'user_based' : True,\n",
    "               'name': 'pearson_baseline',\n",
    "               'shrinkage': 100,\n",
    "               'min_support': 2\n",
    "              } \n",
    "knn_bsl_u = KNNBaseline(k=20, sim_options = sim_options, bsl_options = bsl_options, verbose=False)\n",
    "knn_bsl_u_train_results, knn_bsl_u_test_results = run_surprise(knn_bsl_u, trainset, testset, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['knn_bsl_u'] = knn_bsl_u_train_results['predictions']\n",
    "x_test['knn_bsl_u'] = knn_bsl_u_test_results['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.146945 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:07.647337\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.28482130664126204\n",
      "\n",
      "MAPE : 7.436259813129569\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.395857\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0996065799406272\n",
      "\n",
      "MAPE : 36.29755507802492\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:09.190812\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.175288 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:08.734281\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.30607904299008365\n",
      "\n",
      "MAPE : 7.97386706539947\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.398668\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.099601644867118\n",
      "\n",
      "MAPE : 36.29735193478324\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:10.310272\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.170259 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:09.464980\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.31576677894048366\n",
      "\n",
      "MAPE : 8.210498883118472\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.525147\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995987348277094\n",
      "\n",
      "MAPE : 36.297207609464955\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:11.161142\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.201394 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:09.851494\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.32048691070201407\n",
      "\n",
      "MAPE : 8.320808788699132\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.406371\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995976295274\n",
      "\n",
      "MAPE : 36.29718492212336\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:11.460694\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.551922 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.200529\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.3229609701223102\n",
      "\n",
      "MAPE : 8.378296440525853\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.411106\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995973897288962\n",
      "\n",
      "MAPE : 36.29717476617468\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:12.164289\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.184224 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.416135\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.32427335920646677\n",
      "\n",
      "MAPE : 8.408394669830269\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.522750\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995971972957603\n",
      "\n",
      "MAPE : 36.29716279556012\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:12.124206\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.140410 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.363984\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.32496069565267083\n",
      "\n",
      "MAPE : 8.423899555883011\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.397811\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995974272735307\n",
      "\n",
      "MAPE : 36.297186262342954\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:11.903896\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.180432 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.392823\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.3253105917780476\n",
      "\n",
      "MAPE : 8.431668770113266\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.400698\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995973204214702\n",
      "\n",
      "MAPE : 36.297205029786554\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:11.974698\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.207195 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.432416\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.3254950851316563\n",
      "\n",
      "MAPE : 8.435732606731206\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.400453\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995974008957787\n",
      "\n",
      "MAPE : 36.29721985034951\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:12.041168\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.197000 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.417987\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.3255886186059263\n",
      "\n",
      "MAPE : 8.43797006188539\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.395317\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.099597382954084\n",
      "\n",
      "MAPE : 36.297218592958906\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:12.011447\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.143020 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.363303\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.32563159540519937\n",
      "\n",
      "MAPE : 8.439080676621437\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.511523\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995973196377822\n",
      "\n",
      "MAPE : 36.2972116484705\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:12.019425\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.091987 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.262167\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.32566145826123677\n",
      "\n",
      "MAPE : 8.439869854500483\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.398754\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995972742348685\n",
      "\n",
      "MAPE : 36.29720387090687\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:11.753978\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.142706 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.276441\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.32567726036421146\n",
      "\n",
      "MAPE : 8.44026975449212\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.397476\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995973016217113\n",
      "\n",
      "MAPE : 36.29720602764387\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:11.818090\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.230374 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.310268\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.32568823768423055\n",
      "\n",
      "MAPE : 8.440549500773969\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.523736\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995972539873902\n",
      "\n",
      "MAPE : 36.29720150131839\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:12.065152\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.224954 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.366649\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.3256941021684478\n",
      "\n",
      "MAPE : 8.440686261007745\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.434212\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995972638066436\n",
      "\n",
      "MAPE : 36.297203582880385\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:12.027562\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.271526 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.592863\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.32569779873856736\n",
      "\n",
      "MAPE : 8.440782863002665\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.412493\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995972734440311\n",
      "\n",
      "MAPE : 36.29720480287798\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:12.277654\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.156260 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.268196\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.3256995149023449\n",
      "\n",
      "MAPE : 8.440814419823605\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.395953\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995972839920938\n",
      "\n",
      "MAPE : 36.29720589030274\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:11.821615\n",
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.173948 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.193188\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.32570091011873054\n",
      "\n",
      "MAPE : 8.440844931334226\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.397484\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995972840829953\n",
      "\n",
      "MAPE : 36.29720589964632\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:11.766006\n"
     ]
    }
   ],
   "source": [
    "sim_options = {'user_based' : False,\n",
    "               'name': 'pearson_baseline',\n",
    "               'shrinkage': 100,\n",
    "               'min_support': 2\n",
    "              } \n",
    "# we keep other parameters like regularization parameter and learning_rate as default values.\n",
    "bsl_options = {'method': 'sgd'}\n",
    "\n",
    "scores = {}\n",
    "for k in range(10, 100, 5):\n",
    "    knn_bsl_m = KNNBaseline(k=k, sim_options = sim_options, bsl_options = bsl_options)\n",
    "    knn_bsl_m_train_results, knn_bsl_m_test_results = run_surprise(knn_bsl_m, trainset, testset, verbose=True)\n",
    "    scores[k] = knn_bsl_m_test_results['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(35, 1.0995971972957603),\n",
       " (75, 1.0995972539873902),\n",
       " (80, 1.0995972638066436),\n",
       " (85, 1.0995972734440311),\n",
       " (65, 1.0995972742348685),\n",
       " (90, 1.0995972839920938),\n",
       " (95, 1.0995972840829953),\n",
       " (70, 1.0995973016217113),\n",
       " (60, 1.0995973196377822),\n",
       " (45, 1.0995973204214702),\n",
       " (55, 1.099597382954084),\n",
       " (30, 1.0995973897288962),\n",
       " (50, 1.0995974008957787),\n",
       " (40, 1.0995974272735307),\n",
       " (25, 1.0995976295274),\n",
       " (20, 1.0995987348277094),\n",
       " (15, 1.099601644867118),\n",
       " (10, 1.0996065799406272)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:01.179727 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:10.419539\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.3393620367717291\n",
      "\n",
      "MAPE : 8.890488960757937\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.513133\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0995388120825549\n",
      "\n",
      "MAPE : 36.30006107870331\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:12.113478\n"
     ]
    }
   ],
   "source": [
    "sim_options = {'user_based' : False,\n",
    "               'name': 'pearson_baseline',\n",
    "               'shrinkage': 100,\n",
    "               'min_support': 2\n",
    "              } \n",
    "knn_bsl_m = KNNBaseline(k=35, sim_options = sim_options, bsl_options = bsl_options)\n",
    "knn_bsl_m_train_results, knn_bsl_m_test_results = run_surprise(knn_bsl_m, trainset, testset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['knn_bsl_m'] = knn_bsl_m_train_results['predictions']\n",
    "x_test['knn_bsl_m'] = knn_bsl_m_test_results['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>sur6</th>\n",
       "      <th>sur7</th>\n",
       "      <th>sur8</th>\n",
       "      <th>sur9</th>\n",
       "      <th>sur10</th>\n",
       "      <th>...</th>\n",
       "      <th>smr7</th>\n",
       "      <th>smr8</th>\n",
       "      <th>smr9</th>\n",
       "      <th>smr10</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>bslpr</th>\n",
       "      <th>knn_bsl_u</th>\n",
       "      <th>knn_bsl_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.684725</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.510595</td>\n",
       "      <td>2.941530</td>\n",
       "      <td>3.142870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.976744</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.078008</td>\n",
       "      <td>2.280042</td>\n",
       "      <td>2.402025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.076835</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.366520</td>\n",
       "      <td>4.331044</td>\n",
       "      <td>4.315673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.730769</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>2.717042</td>\n",
       "      <td>2.419183</td>\n",
       "      <td>2.278270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>2.908390</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.681138</td>\n",
       "      <td>2.597700</td>\n",
       "      <td>2.463155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sur1  sur2  sur3  sur4  sur5  sur6  sur7  sur8  sur9  sur10    ...      \\\n",
       "0   4.0   3.0   4.0   5.0   3.0   4.0   3.0   3.0   4.0    4.0    ...       \n",
       "1   4.0   4.0   3.0   4.0   3.0   2.0   3.0   3.0   5.0    3.0    ...       \n",
       "2   1.0   4.0   1.0   4.0   4.0   4.0   4.0   2.0   4.0    3.0    ...       \n",
       "3   1.0   4.0   3.0   3.0   2.0   3.0   3.0   3.0   4.0    2.0    ...       \n",
       "4   5.0   1.0   2.0   3.0   3.0   2.0   4.0   3.0   3.0    4.0    ...       \n",
       "\n",
       "       smr7      smr8      smr9     smr10      MAvg      UAvg      GAvg  \\\n",
       "0  2.000000  3.000000  4.000000  5.000000  3.684725  3.333333  3.581679   \n",
       "1  3.333333  3.333333  3.333333  3.333333  2.976744  3.333333  3.581679   \n",
       "2  4.000000  4.000000  3.000000  4.000000  3.076835  3.250000  3.581679   \n",
       "3  2.000000  3.000000  2.000000  2.000000  2.730769  2.660000  3.581679   \n",
       "4  4.400000  4.400000  4.400000  4.400000  2.908390  4.400000  3.581679   \n",
       "\n",
       "      bslpr  knn_bsl_u  knn_bsl_m  \n",
       "0  3.510595   2.941530   3.142870  \n",
       "1  3.078008   2.280042   2.402025  \n",
       "2  3.366520   4.331044   4.315673  \n",
       "3  2.717042   2.419183   2.278270  \n",
       "4  3.681138   2.597700   2.463155  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 44s, sys: 168 ms, total: 3min 45s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = xgb.XGBRegressor(n_jobs=16, random_state=42, n_estimators=1000, colsample_bytree=0.1, learning_rate=0.15,\n",
    "                        max_depth=3, subsample=0.5, reg_alpha=0.01)\n",
    "model.fit(x_train, y_train, eval_metric='rmse', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8200225730633288 24.298012499069984\n",
      "1.1264115365292955 34.91394168030328\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "rmse_train, mape_train = get_error_metrics(y_train.values, y_train_pred)\n",
    "print(rmse_train, mape_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "rmse_test, mape_test = get_error_metrics(y_test.values, y_test_pred)\n",
    "print(rmse_test, mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:   36.1s remaining:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 s, sys: 488 ms, total: 14 s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trr, tsr, model = run_xgb(train_frames=(x_train, y_train), test_frames=(x_test, y_test), \n",
    "        eval_metric=get_error_metrics, tuning=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.3,\n",
       " 'learning_rate': 0.2,\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 200,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8266462829646578 24.492552927342455\n",
      "1.1206661498408128 35.201180931377756\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.best_estimator_.predict(x_train)\n",
    "rmse_train, mape_train = get_error_metrics(y_train.values, y_train_pred)\n",
    "print(rmse_train, mape_train)\n",
    "y_test_pred = model.best_estimator_.predict(x_test)\n",
    "rmse_test, mape_test = get_error_metrics(y_test.values, y_test_pred)\n",
    "print(rmse_test, mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, SVDpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for f in [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]:\n",
    "    svd = SVD(n_factors=f, biased=True, random_state=15, verbose=False)\n",
    "    svd_train_results, svd_test_results = run_surprise(svd, trainset, testset, verbose=False)\n",
    "    scores[f] = svd_test_results['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(150, 1.0995032392632291),\n",
       " (400, 1.0995109689989067),\n",
       " (450, 1.099522111259098),\n",
       " (100, 1.0995231661001237),\n",
       " (200, 1.0995259544926652),\n",
       " (500, 1.0995287041765225),\n",
       " (300, 1.099534729728022),\n",
       " (50, 1.0995477347957328),\n",
       " (250, 1.0995729404306134),\n",
       " (350, 1.099580094229309)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Done. time taken : 0:00:25.835961 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:01.458112\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.26271072084651853\n",
      "\n",
      "MAPE : 7.570615715767446\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.368714\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0994738388416014\n",
      "\n",
      "MAPE : 36.283853431003365\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:27.663507\n"
     ]
    }
   ],
   "source": [
    "svd = SVD(n_factors=150, biased=True, random_state=15, verbose=True, n_epochs=50)\n",
    "svd_train_results, svd_test_results = run_surprise(svd, trainset, testset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 7.570615715767446,\n",
       " 'predictions': array([2.91835994, 2.11119893, 4.68831639, ..., 3.89304097, 3.79625456,\n",
       "        2.05792307]),\n",
       " 'rmse': 0.26271072084651853}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['svd'] = svd_train_results['rmse'] \n",
    "x_test['svd'] = svd_test_results['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>sur6</th>\n",
       "      <th>sur7</th>\n",
       "      <th>sur8</th>\n",
       "      <th>sur9</th>\n",
       "      <th>sur10</th>\n",
       "      <th>...</th>\n",
       "      <th>smr8</th>\n",
       "      <th>smr9</th>\n",
       "      <th>smr10</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>bslpr</th>\n",
       "      <th>knn_bsl_u</th>\n",
       "      <th>knn_bsl_m</th>\n",
       "      <th>svd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.684725</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.510595</td>\n",
       "      <td>2.941530</td>\n",
       "      <td>3.142870</td>\n",
       "      <td>0.262711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.976744</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.078008</td>\n",
       "      <td>2.280042</td>\n",
       "      <td>2.402025</td>\n",
       "      <td>0.262711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.076835</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.366520</td>\n",
       "      <td>4.331044</td>\n",
       "      <td>4.315673</td>\n",
       "      <td>0.262711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.730769</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>2.717042</td>\n",
       "      <td>2.419183</td>\n",
       "      <td>2.278270</td>\n",
       "      <td>0.262711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>2.908390</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.581679</td>\n",
       "      <td>3.681138</td>\n",
       "      <td>2.597700</td>\n",
       "      <td>2.463155</td>\n",
       "      <td>0.262711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sur1  sur2  sur3  sur4  sur5  sur6  sur7  sur8  sur9  sur10    ...     \\\n",
       "0   4.0   3.0   4.0   5.0   3.0   4.0   3.0   3.0   4.0    4.0    ...      \n",
       "1   4.0   4.0   3.0   4.0   3.0   2.0   3.0   3.0   5.0    3.0    ...      \n",
       "2   1.0   4.0   1.0   4.0   4.0   4.0   4.0   2.0   4.0    3.0    ...      \n",
       "3   1.0   4.0   3.0   3.0   2.0   3.0   3.0   3.0   4.0    2.0    ...      \n",
       "4   5.0   1.0   2.0   3.0   3.0   2.0   4.0   3.0   3.0    4.0    ...      \n",
       "\n",
       "       smr8      smr9     smr10      MAvg      UAvg      GAvg     bslpr  \\\n",
       "0  3.000000  4.000000  5.000000  3.684725  3.333333  3.581679  3.510595   \n",
       "1  3.333333  3.333333  3.333333  2.976744  3.333333  3.581679  3.078008   \n",
       "2  4.000000  3.000000  4.000000  3.076835  3.250000  3.581679  3.366520   \n",
       "3  3.000000  2.000000  2.000000  2.730769  2.660000  3.581679  2.717042   \n",
       "4  4.400000  4.400000  4.400000  2.908390  4.400000  3.581679  3.681138   \n",
       "\n",
       "   knn_bsl_u  knn_bsl_m       svd  \n",
       "0   2.941530   3.142870  0.262711  \n",
       "1   2.280042   2.402025  0.262711  \n",
       "2   4.331044   4.315673  0.262711  \n",
       "3   2.419183   2.278270  0.262711  \n",
       "4   2.597700   2.463155  0.262711  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 0:02:08.392582 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:06.524472\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.6010341577012868\n",
      "\n",
      "MAPE : 17.52519704951758\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.547750\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.099877282671265\n",
      "\n",
      "MAPE : 36.291039253452595\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:02:15.466163\n",
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 0:03:33.134487 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:06.746635\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.5067929210715073\n",
      "\n",
      "MAPE : 14.678962635729379\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.521291\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.099799558877154\n",
      "\n",
      "MAPE : 36.28760187690324\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:03:40.403354\n",
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 0:05:07.332915 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:07.905118\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.44638523813476927\n",
      "\n",
      "MAPE : 12.926598776536972\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.375644\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0997128239715912\n",
      "\n",
      "MAPE : 36.2930857110623\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:05:15.616119\n",
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 0:06:33.336568 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:08.108820\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.40278883181830255\n",
      "\n",
      "MAPE : 11.641615392390376\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.520545\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0997756953280993\n",
      "\n",
      "MAPE : 36.30228561868284\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:06:41.967212\n",
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 0:07:56.667096 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:08.291594\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.3722182529229552\n",
      "\n",
      "MAPE : 10.715324019131762\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.378924\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0998891821067107\n",
      "\n",
      "MAPE : 36.30272773482264\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:08:05.338850\n",
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 0:10:15.380848 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:08.482735\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.3456424349987657\n",
      "\n",
      "MAPE : 9.941092274870583\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.540856\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0997653153101905\n",
      "\n",
      "MAPE : 36.29628201189966\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:10:24.405337\n",
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 0:12:38.403293 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:08.897099\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.32663949185516145\n",
      "\n",
      "MAPE : 9.41269723368542\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.380635\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0998112494446333\n",
      "\n",
      "MAPE : 36.301582897460314\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:12:47.682693\n",
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 0:15:04.478433 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:09.012040\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.3125908763694849\n",
      "\n",
      "MAPE : 8.973939855004895\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.521529\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0997181018480295\n",
      "\n",
      "MAPE : 36.297058020094234\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:15:14.013777\n",
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing epoch 19\n",
      "Done. time taken : 0:17:32.425124 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:08.958921\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.29907720659526016\n",
      "\n",
      "MAPE : 8.601186721311834\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.384797\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.09969339886896\n",
      "\n",
      "MAPE : 36.29900525753309\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:17:41.769824\n",
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 0:19:51.693275 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:09.276849\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.28735940037725904\n",
      "\n",
      "MAPE : 8.223607905862805\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.559445\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0997444202673292\n",
      "\n",
      "MAPE : 36.30003324790059\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:20:01.531300\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for f in [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]:\n",
    "    svdpp = SVDpp(n_factors=f, random_state=15, verbose=True)\n",
    "    svdpp_train_results, svdpp_test_results = run_surprise(svdpp, trainset, testset, verbose=True)\n",
    "    scores[f] = svdpp_test_results['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(450, 1.09969339886896),\n",
       " (150, 1.0997128239715912),\n",
       " (400, 1.0997181018480295),\n",
       " (500, 1.0997444202673292),\n",
       " (300, 1.0997653153101905),\n",
       " (200, 1.0997756953280993),\n",
       " (100, 1.099799558877154),\n",
       " (350, 1.0998112494446333),\n",
       " (50, 1.099877282671265),\n",
       " (250, 1.0998891821067107)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 0:17:20.478503 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:09.224921\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.29907720659526016\n",
      "\n",
      "MAPE : 8.601186721311834\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.384511\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.09969339886896\n",
      "\n",
      "MAPE : 36.29900525753309\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:17:30.089927\n"
     ]
    }
   ],
   "source": [
    "svdpp = SVDpp(n_factors=450, random_state=15, verbose=True)\n",
    "svdpp_train_results, svdpp_test_results = run_surprise(svdpp, trainset, testset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['svdpp'] = svdpp_train_results['rmse'] \n",
    "x_test['svdpp'] = svdpp_test_results['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['rating'] = y_train\n",
    "x_test['rating'] = y_test\n",
    "x_train.to_csv('./dataset/x_train_10000_1000.csv', index=False)\n",
    "x_test.to_csv('./dataset/x_test_10000_1000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop('rating', axis=1, inplace=True)\n",
    "x_test.drop('rating', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:  1.7min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 11.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 8s, sys: 568 ms, total: 13min 8s\n",
      "Wall time: 24min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trr, tsr, model = run_xgb(train_frames=(x_train, y_train), test_frames=(x_test, y_test), \n",
    "        eval_metric=get_error_metrics, tuning=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5886822832579691 16.591248704157714\n",
      "1.1530419672171563 34.253363173622105\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.best_estimator_.predict(x_train)\n",
    "rmse_train, mape_train = get_error_metrics(y_train.values, y_train_pred)\n",
    "print(rmse_train, mape_train)\n",
    "y_test_pred = model.best_estimator_.predict(x_test)\n",
    "rmse_test, mape_test = get_error_metrics(y_test.values, y_test_pred)\n",
    "print(rmse_test, mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 10,\n",
       " 'n_estimators': 2000,\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the dataset of 25000 x 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('./dataset/train_25000_3000.csv',\n",
    "                     names = ['user', 'movie',\n",
    "                                    'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "                                    'sur6', 'sur7', 'sur8', 'sur9', 'sur10',\n",
    "                                    'smr1', 'smr2', 'smr3', 'smr4', 'smr5',\n",
    "                                    'smr6', 'smr7', 'smr8', 'smr9', 'smr10',\n",
    "                                    'MAvg', 'UAvg', 'GAvg', 'rating'], header=None)\n",
    "\n",
    "x_train.drop(['user', 'movie'], axis=1, inplace=True)\n",
    "y_train = x_train.rating\n",
    "x_train.drop(['rating'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('./dataset/test_25000_3000.csv', \n",
    "                    names = ['user', 'movie',\n",
    "                                    'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "                                    'sur6', 'sur7', 'sur8', 'sur9', 'sur10',\n",
    "                                    'smr1', 'smr2', 'smr3', 'smr4', 'smr5',\n",
    "                                    'smr6', 'smr7', 'smr8', 'smr9', 'smr10',\n",
    "                                    'MAvg', 'UAvg', 'GAvg', 'rating'], header=None)\n",
    "x_test.drop(['user', 'movie'], axis=1, inplace=True)\n",
    "y_test = x_test.rating\n",
    "x_test.drop(['rating'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856986, 23)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261693, 23)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 6s, sys: 1.82 s, total: 3min 7s\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trr, tsr, model = run_xgb(train_frames=(x_train, y_train), test_frames=(x_test, y_test), \n",
    "        eval_metric=get_error_metrics, tuning=False, n_jobs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 25.60607327683226, 'rmse': 0.854572352919758}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 33.6849388024272, 'rmse': 1.096860802799888}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed: 13.1min remaining: 10.7min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trr, tsr, model = run_xgb(train_frames=(x_train, y_train), test_frames=(x_test, y_test), \n",
    "        eval_metric=get_error_metrics, tuning=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 24.617162352130688, 'rmse': 0.8322098236809364}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 32.96068961518468, 'rmse': 1.1460588022296534}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_train = pd.read_csv('./dataset/train_25000_3000.csv',\n",
    "                     names = ['user', 'movie',\n",
    "                                    'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "                                    'sur6', 'sur7', 'sur8', 'sur9', 'sur10',\n",
    "                                    'smr1', 'smr2', 'smr3', 'smr4', 'smr5',\n",
    "                                    'smr6', 'smr7', 'smr8', 'smr9', 'smr10',\n",
    "                                    'MAvg', 'UAvg', 'GAvg', 'rating'], header=None)\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "train_data = Dataset.load_from_df(reg_train[['user', 'movie', 'rating']], reader)\n",
    "trainset = train_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1129620, 2, 3), (2407458, 5582, 4), (668855, 6677, 3)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_test = pd.read_csv('./dataset/test_25000_3000.csv',\n",
    "                     names = ['user', 'movie',\n",
    "                                    'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "                                    'sur6', 'sur7', 'sur8', 'sur9', 'sur10',\n",
    "                                    'smr1', 'smr2', 'smr3', 'smr4', 'smr5',\n",
    "                                    'smr6', 'smr7', 'smr8', 'smr9', 'smr10',\n",
    "                                    'MAvg', 'UAvg', 'GAvg', 'rating'], header=None)\n",
    "testset = list(zip(reg_test.user.values, reg_test.movie.values, reg_test.rating.values))\n",
    "testset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for lr in [10, 1, 0.1, 0.01, 0.001, 0.003, 0.005, 0.007, 0.0001]:\n",
    "    bsl_options = {'method': 'sgd',\n",
    "                   'learning_rate': lr}\n",
    "    bsl_algo = BaselineOnly(bsl_options=bsl_options, verbose=False)\n",
    "    # run this algorithm.., It will return the train and test results..\n",
    "    bsl_train_results, bsl_test_results = run_surprise(bsl_algo, trainset, testset, verbose=False)\n",
    "    scores[lr] = bsl_test_results['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.001, 1.0816719448109384),\n",
       " (0.003, 1.0817022917347872),\n",
       " (0.005, 1.0819683403064757),\n",
       " (0.007, 1.0822509061747585),\n",
       " (0.01, 1.0826597487620286),\n",
       " (0.0001, 1.0832897290093344),\n",
       " (0.1, 1.0896225635772798),\n",
       " (10, 1.238800386453538),\n",
       " (1, 1.4150266238135194)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Done. time taken : 0:00:06.861425 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:08.343935\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.9221340991490828\n",
      "\n",
      "MAPE : 28.642423887479605\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:03.231457\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0816719448109384\n",
      "\n",
      "MAPE : 34.043085698379784\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:18.438229\n"
     ]
    }
   ],
   "source": [
    "bsl_options = {'method': 'sgd',\n",
    "                   'learning_rate': 0.001}\n",
    "bsl_algo = BaselineOnly(bsl_options=bsl_options, verbose=True)\n",
    "bsl_train_results, bsl_test_results = run_surprise(bsl_algo, trainset, testset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['bslpr'] = bsl_train_results['predictions']\n",
    "x_test['bslpr'] = bsl_test_results['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# we specify , how to compute similarities and what to consider with sim_options to our algorithm\n",
    "sim_options = {'user_based' : True,\n",
    "               'name': 'pearson_baseline',\n",
    "               'shrinkage': 100,\n",
    "               'min_support': 2\n",
    "              } \n",
    "# we keep other parameters like regularization parameter and learning_rate as default values.\n",
    "bsl_options = {'method': 'sgd'} \n",
    "scores = {}\n",
    "for k in range(10, 100, 5):\n",
    "    knn_bsl_u = KNNBaseline(k=k, sim_options = sim_options, bsl_options = bsl_options, verbose=False)\n",
    "    knn_bsl_u_train_results, knn_bsl_u_test_results = run_surprise(knn_bsl_u, trainset, testset, verbose=False)\n",
    "    scores[k] = knn_bsl_u_test_results['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(70, 1.081922181172459),\n",
       " (60, 1.0819259906791825),\n",
       " (40, 1.0819267112455815),\n",
       " (65, 1.081927291816672),\n",
       " (55, 1.0819288467283283),\n",
       " (50, 1.0819293322338353),\n",
       " (45, 1.0819322182617994),\n",
       " (30, 1.0819324281789666),\n",
       " (35, 1.0819339165590731),\n",
       " (25, 1.0819466434445217),\n",
       " (20, 1.081960174781031),\n",
       " (15, 1.0819770600416754),\n",
       " (10, 1.0820212062220682)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Estimating biases using sgd...\n"
     ]
    }
   ],
   "source": [
    "knn_bsl_u = KNNBaseline(k=70, sim_options = sim_options, bsl_options = bsl_options, verbose=True)\n",
    "knn_bsl_u_train_results, knn_bsl_u_test_results = run_surprise(knn_bsl_u, trainset, testset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 34.04040310973702,\n",
       " 'predictions': array([3.58758136, 3.58758136, 3.39395582, ..., 3.99276318, 3.99276318,\n",
       "        3.99276318]),\n",
       " 'rmse': 1.081922181172459}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_bsl_u_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['knn_bsl_u'] = knn_bsl_u_train_results['predictions']\n",
    "x_test['knn_bsl_u'] = knn_bsl_u_test_results['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>sur6</th>\n",
       "      <th>sur7</th>\n",
       "      <th>sur8</th>\n",
       "      <th>sur9</th>\n",
       "      <th>sur10</th>\n",
       "      <th>...</th>\n",
       "      <th>smr6</th>\n",
       "      <th>smr7</th>\n",
       "      <th>smr8</th>\n",
       "      <th>smr9</th>\n",
       "      <th>smr10</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>bslpr</th>\n",
       "      <th>knn_bsl_u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>3.882353</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>3.679824</td>\n",
       "      <td>4.982729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.163265</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>2.968929</td>\n",
       "      <td>3.167275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.774065</td>\n",
       "      <td>2.945946</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>3.447917</td>\n",
       "      <td>3.249298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.515200</td>\n",
       "      <td>3.850467</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>4.142028</td>\n",
       "      <td>4.782319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.386404</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>4.323936</td>\n",
       "      <td>4.942732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sur1  sur2  sur3  sur4  sur5  sur6  sur7  sur8  sur9  sur10    ...      \\\n",
       "0   5.0   5.0   3.0   4.0   4.0   4.0   4.0   4.0   3.0    4.0    ...       \n",
       "1   3.0   5.0   5.0   4.0   2.0   3.0   3.0   3.0   4.0    4.0    ...       \n",
       "2   4.0   3.0   2.0   3.0   3.0   4.0   2.0   3.0   2.0    3.0    ...       \n",
       "3   2.0   4.0   4.0   4.0   3.0   4.0   3.0   4.0   3.0    2.0    ...       \n",
       "4   4.0   4.0   4.0   4.0   3.0   2.0   4.0   4.0   3.0    3.0    ...       \n",
       "\n",
       "   smr6  smr7  smr8  smr9  smr10      MAvg      UAvg      GAvg     bslpr  \\\n",
       "0   4.0   3.0   4.0   2.0    5.0  3.611111  3.882353  3.587581  3.679824   \n",
       "1   4.0   3.0   5.0   4.0    3.0  3.163265  3.714286  3.587581  2.968929   \n",
       "2   4.0   3.0   4.0   4.0    4.0  2.774065  2.945946  3.587581  3.447917   \n",
       "3   3.0   4.0   4.0   3.0    4.0  3.515200  3.850467  3.587581  4.142028   \n",
       "4   4.0   3.0   4.0   4.0    5.0  3.386404  3.666667  3.587581  4.323936   \n",
       "\n",
       "   knn_bsl_u  \n",
       "0   4.982729  \n",
       "1   3.167275  \n",
       "2   3.249298  \n",
       "3   4.782319  \n",
       "4   4.942732  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:19.124201 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:02:48.211354\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.5184554371223534\n",
      "\n",
      "MAPE : 14.564513589620564\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:03.717117\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0820863958149332\n",
      "\n",
      "MAPE : 34.04254851269998\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:03:11.054712\n"
     ]
    }
   ],
   "source": [
    "sim_options = {'user_based' : False,\n",
    "               'name': 'pearson_baseline',\n",
    "               'shrinkage': 100,\n",
    "               'min_support': 2\n",
    "              } \n",
    "bsl_options = {'method': 'sgd'}\n",
    "knn_bsl_m = KNNBaseline(k=70, sim_options = sim_options, bsl_options = bsl_options, verbose=True)\n",
    "knn_bsl_m_train_results, knn_bsl_m_test_results = run_surprise(knn_bsl_m, trainset, testset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['knn_bsl_m'] = knn_bsl_m_train_results['predictions']\n",
    "x_test['knn_bsl_m'] = knn_bsl_m_test_results['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>sur6</th>\n",
       "      <th>sur7</th>\n",
       "      <th>sur8</th>\n",
       "      <th>sur9</th>\n",
       "      <th>sur10</th>\n",
       "      <th>...</th>\n",
       "      <th>smr7</th>\n",
       "      <th>smr8</th>\n",
       "      <th>smr9</th>\n",
       "      <th>smr10</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>bslpr</th>\n",
       "      <th>knn_bsl_u</th>\n",
       "      <th>knn_bsl_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>3.882353</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>3.679824</td>\n",
       "      <td>4.982729</td>\n",
       "      <td>4.886922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.163265</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>2.968929</td>\n",
       "      <td>3.167275</td>\n",
       "      <td>3.122327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.774065</td>\n",
       "      <td>2.945946</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>3.447917</td>\n",
       "      <td>3.249298</td>\n",
       "      <td>3.413867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.515200</td>\n",
       "      <td>3.850467</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>4.142028</td>\n",
       "      <td>4.782319</td>\n",
       "      <td>4.512588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.386404</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>4.323936</td>\n",
       "      <td>4.942732</td>\n",
       "      <td>4.937010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sur1  sur2  sur3  sur4  sur5  sur6  sur7  sur8  sur9  sur10    ...      \\\n",
       "0   5.0   5.0   3.0   4.0   4.0   4.0   4.0   4.0   3.0    4.0    ...       \n",
       "1   3.0   5.0   5.0   4.0   2.0   3.0   3.0   3.0   4.0    4.0    ...       \n",
       "2   4.0   3.0   2.0   3.0   3.0   4.0   2.0   3.0   2.0    3.0    ...       \n",
       "3   2.0   4.0   4.0   4.0   3.0   4.0   3.0   4.0   3.0    2.0    ...       \n",
       "4   4.0   4.0   4.0   4.0   3.0   2.0   4.0   4.0   3.0    3.0    ...       \n",
       "\n",
       "   smr7  smr8  smr9  smr10      MAvg      UAvg      GAvg     bslpr  knn_bsl_u  \\\n",
       "0   3.0   4.0   2.0    5.0  3.611111  3.882353  3.587581  3.679824   4.982729   \n",
       "1   3.0   5.0   4.0    3.0  3.163265  3.714286  3.587581  2.968929   3.167275   \n",
       "2   3.0   4.0   4.0    4.0  2.774065  2.945946  3.587581  3.447917   3.249298   \n",
       "3   4.0   4.0   3.0    4.0  3.515200  3.850467  3.587581  4.142028   4.782319   \n",
       "4   3.0   4.0   4.0    5.0  3.386404  3.666667  3.587581  4.323936   4.942732   \n",
       "\n",
       "   knn_bsl_m  \n",
       "0   4.886922  \n",
       "1   3.122327  \n",
       "2   3.413867  \n",
       "3   4.512588  \n",
       "4   4.937010  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, SVDpp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [26:09<00:00, 223.43s/it]\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for f in tqdm([50, 100, 150, 200, 250, 300, 350, 400, 450, 500]):\n",
    "    svd = SVD(n_factors=f, biased=True, random_state=15, verbose=False)\n",
    "    svd_train_results, svd_test_results = run_surprise(svd, trainset, testset, verbose=False)\n",
    "    scores[f] = svd_test_results['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(450, 1.0817583429460766),\n",
       " (500, 1.0817590126894747),\n",
       " (400, 1.0817847522902897),\n",
       " (150, 1.0817918964076993),\n",
       " (300, 1.0818230447552493),\n",
       " (250, 1.0818553202819787),\n",
       " (350, 1.0818567076090326),\n",
       " (200, 1.0818630851340787),\n",
       " (100, 1.081876187303056),\n",
       " (50, 1.0818879815173739)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Done. time taken : 0:04:07.661219 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:11.108487\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.4706261759813944\n",
      "\n",
      "MAPE : 13.739027251917435\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:03.262811\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0817583429460766\n",
      "\n",
      "MAPE : 33.99540588009756\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:04:22.033287\n"
     ]
    }
   ],
   "source": [
    "svd = SVD(n_factors=450, biased=True, random_state=15, verbose=True)\n",
    "svd_train_results, svd_test_results = run_surprise(svd, trainset, testset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['svd'] = svd_train_results['predictions']\n",
    "x_test['svd'] = svd_test_results['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>sur6</th>\n",
       "      <th>sur7</th>\n",
       "      <th>sur8</th>\n",
       "      <th>sur9</th>\n",
       "      <th>sur10</th>\n",
       "      <th>...</th>\n",
       "      <th>smr8</th>\n",
       "      <th>smr9</th>\n",
       "      <th>smr10</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>bslpr</th>\n",
       "      <th>knn_bsl_u</th>\n",
       "      <th>knn_bsl_m</th>\n",
       "      <th>svd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>3.882353</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>3.679824</td>\n",
       "      <td>4.982729</td>\n",
       "      <td>4.886922</td>\n",
       "      <td>4.631519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.163265</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>2.968929</td>\n",
       "      <td>3.167275</td>\n",
       "      <td>3.122327</td>\n",
       "      <td>3.097232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.774065</td>\n",
       "      <td>2.945946</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>3.447917</td>\n",
       "      <td>3.249298</td>\n",
       "      <td>3.413867</td>\n",
       "      <td>3.151565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.515200</td>\n",
       "      <td>3.850467</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>4.142028</td>\n",
       "      <td>4.782319</td>\n",
       "      <td>4.512588</td>\n",
       "      <td>4.513377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.386404</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.587581</td>\n",
       "      <td>4.323936</td>\n",
       "      <td>4.942732</td>\n",
       "      <td>4.937010</td>\n",
       "      <td>4.758461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sur1  sur2  sur3  sur4  sur5  sur6  sur7  sur8  sur9  sur10    ...     \\\n",
       "0   5.0   5.0   3.0   4.0   4.0   4.0   4.0   4.0   3.0    4.0    ...      \n",
       "1   3.0   5.0   5.0   4.0   2.0   3.0   3.0   3.0   4.0    4.0    ...      \n",
       "2   4.0   3.0   2.0   3.0   3.0   4.0   2.0   3.0   2.0    3.0    ...      \n",
       "3   2.0   4.0   4.0   4.0   3.0   4.0   3.0   4.0   3.0    2.0    ...      \n",
       "4   4.0   4.0   4.0   4.0   3.0   2.0   4.0   4.0   3.0    3.0    ...      \n",
       "\n",
       "   smr8  smr9  smr10      MAvg      UAvg      GAvg     bslpr  knn_bsl_u  \\\n",
       "0   4.0   2.0    5.0  3.611111  3.882353  3.587581  3.679824   4.982729   \n",
       "1   5.0   4.0    3.0  3.163265  3.714286  3.587581  2.968929   3.167275   \n",
       "2   4.0   4.0    4.0  2.774065  2.945946  3.587581  3.447917   3.249298   \n",
       "3   4.0   3.0    4.0  3.515200  3.850467  3.587581  4.142028   4.782319   \n",
       "4   4.0   4.0    5.0  3.386404  3.666667  3.587581  4.323936   4.942732   \n",
       "\n",
       "   knn_bsl_m       svd  \n",
       "0   4.886922  4.631519  \n",
       "1   3.122327  3.097232  \n",
       "2   3.413867  3.151565  \n",
       "3   4.512588  4.513377  \n",
       "4   4.937010  4.758461  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "trr, tsr, _ = run_xgb(train_frames=(x_train, y_train), test_frames=(x_test, y_test), \n",
    "        eval_metric=get_error_metrics, tuning=False, n_jobs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 25.60601509179718, 'rmse': 0.8545724040845634}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 33.68493102838425, 'rmse': 1.096862228380405}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:  4.3min remaining:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 17.4min finished\n"
     ]
    }
   ],
   "source": [
    "trr, tsr, model = run_xgb(train_frames=(x_train, y_train), test_frames=(x_test, y_test), \n",
    "        eval_metric=get_error_metrics, tuning=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 25.087553813471818, 'rmse': 0.8429942025454135}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 33.7782628644331, 'rmse': 1.1020239157292728}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_data_1.txt\t\t      sample_sparse_matrix.npz\r\n",
      "combined_data_2.txt\t\t      sample_sparse_test_matrix_10000_1000.npz\r\n",
      "combined_data_3.txt\t\t      sample_sparse_test_matrix_25000_3000.npz\r\n",
      "combined_data_4.txt\t\t      sample_sparse_test_matrix.npz\r\n",
      "movie_titles.csv\t\t      test_10000_1000.csv\r\n",
      "probe.txt\t\t\t      test_25000_3000.csv\r\n",
      "qualifying.txt\t\t\t      test.csv\r\n",
      "README\t\t\t\t      train_10000_1000.csv\r\n",
      "reviews_test_sparse.npz\t\t      train_25000_3000.csv\r\n",
      "reviews_train_sparse.npz\t      train.csv\r\n",
      "sample_sparse_matrix_10000_1000.npz   x_test_10000_1000.csv\r\n",
      "sample_sparse_matrix_25000_3000.npz   x_train_10000_1000.csv\r\n",
      "sample_sparse_matrix_80000_10000.npz\r\n"
     ]
    }
   ],
   "source": [
    "!ls dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.datasets import fetch_movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_movielens(min_rating=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 2153 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d249c8495052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'helpers'"
     ]
    }
   ],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
